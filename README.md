# Сравнение моделей HuggingFace

Консольное приложение для сравнения различных моделей из HuggingFace по следующим параметрам:
- Время ответа (мс)
- Количество токенов (входных и выходных)
- Стоимость (для платных моделей)
- Качество ответов

## Возможности

- Вызов одного запроса на нескольких моделях одновременно
- Замер времени ответа для каждой модели
- Подсчет токенов (приблизительная оценка)
- Расчет стоимости для платных моделей
- Сравнительная таблица результатов
- Детальный вывод ответов каждой модели
- Статистика (самая быстрая модель, больше всего токенов и т.д.)

## Требования

- Java 17 или выше
- Kotlin 2.2.20
- Gradle 8.x
- HuggingFace API токен

## Установка и настройка

### 1. Получение API токена HuggingFace

1. Перейдите на https://huggingface.co/settings/tokens
2. Создайте новый токен (Access Token)
3. Скопируйте токен

### 2. Настройка токена

Создайте файл `local.properties` в корне проекта:

```bash
cp local.properties.example local.properties
```

Откройте `local.properties` и укажите ваш токен:

```properties
huggingface.api.token=ваш_токен_здесь
```

**Примечание:** Файл `local.properties` не попадет в Git, так как добавлен в `.gitignore`.

### 3. Сборка проекта

```bash
./gradlew build
```

## Использование

### Запуск приложения

```bash
./gradlew run
```

### Интерактивный режим

После запуска приложение попросит вас ввести запрос:

```
================================================================================
Сравнение моделей HuggingFace
================================================================================

Введите ваш запрос для моделей:
```

Введите свой запрос (например, "Напиши короткое стихотворение о весне") и нажмите Enter.

### Пример вывода

```
================================================================================
СРАВНИТЕЛЬНАЯ ТАБЛИЦА
================================================================================

Модель                                   | Время (мс) | Вход.токены | Вых.токены | Стоимость
--------------------------------------------------------------------------------
bloom-560m                               |       1234 |           8 |         50 | Бесплатно
Llama-2-7b-chat-hf                       |       2456 |           8 |        120 | Бесплатно
Mistral-7B-Instruct-v0.1                 |       1876 |           8 |         95 | Бесплатно

СТАТИСТИКА:
  Самая быстрая модель: bigscience/bloom-560m (1234 мс)
  Самая медленная модель: meta-llama/Llama-2-7b-chat-hf (2456 мс)
  Больше всего токенов в ответе: meta-llama/Llama-2-7b-chat-hf (120 токенов)
```

## Настройка моделей

По умолчанию приложение сравнивает следующие модели:
- `bigscience/bloom-560m` - небольшая модель BLOOM
- `meta-llama/Llama-2-7b-chat-hf` - Llama 2 Chat (может требовать дополнительной авторизации)
- `mistralai/Mistral-7B-Instruct-v0.1` - Mistral Instruct

Вы можете изменить список моделей в файле `src/main/kotlin/Main.kt`:

```kotlin
val models = listOf(
    "bigscience/bloom-560m",
    "meta-llama/Llama-2-7b-chat-hf",
    "mistralai/Mistral-7B-Instruct-v0.1"
    // Добавьте свои модели здесь
)
```

### Популярные модели HuggingFace

- `bigscience/bloom-560m` - компактная версия BLOOM
- `gpt2` - классическая GPT-2
- `EleutherAI/gpt-neo-1.3B` - GPT-Neo 1.3B
- `facebook/opt-1.3b` - OPT от Meta
- `google/flan-t5-base` - FLAN-T5
- `mistralai/Mistral-7B-v0.1` - Mistral 7B
- `meta-llama/Llama-2-7b-hf` - Llama 2 7B

**Примечание:** Некоторые модели (например, Llama) могут требовать дополнительной авторизации через HuggingFace.

## Структура проекта

```
AIAdvent/
├── src/main/kotlin/
│   ├── Main.kt              # Основной файл приложения
│   └── HuggingFaceClient.kt # Клиент для работы с HuggingFace API
├── build.gradle.kts         # Конфигурация Gradle
└── README.md               # Этот файл
```

## Зависимости

- `okhttp3:okhttp:4.12.0` - HTTP клиент для API запросов
- `kotlinx-serialization-json:1.6.0` - JSON сериализация
- `kotlinx-coroutines-core:1.7.3` - Корутины для асинхронных операций

## Ограничения

1. **Оценка токенов** - приблизительная (4 символа = 1 токен)
2. **Стоимость** - большинство моделей на HuggingFace Inference API бесплатны
3. **Доступ к моделям** - некоторые модели требуют дополнительной авторизации
4. **Лимиты API** - бесплатный API имеет ограничения по количеству запросов

## Устранение проблем

### Ошибка: "ОШИБКА: API токен не найден!"

Убедитесь, что файл `local.properties` существует и содержит корректный токен:

```properties
huggingface.api.token=ваш_токен_здесь
```

### Ошибка: HTTP 401 или 403

- Проверьте корректность API токена
- Убедитесь, что у вас есть доступ к выбранной модели (некоторые требуют подтверждения лицензии)

### Ошибка: HTTP 503 "Model is currently loading"

Модель загружается на серверах HuggingFace. Подождите минуту и попробуйте снова.

## Лицензия

MIT License

## Авторы

Создано как учебный проект для сравнения моделей HuggingFace.